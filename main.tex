\documentclass[10pt,conference]{ieeeconf}
\usepackage{algorithm}
\usepackage{algpseudocode}


\begin{document}


\nocite{PRM}


\author{Sterling McLeod}
\title {Real-time Robot Motion Planning: A Survey}
\date {2016}

\maketitle

\renewcommand{\algorithmicforall}{\textbf{for each}}

\section{Problem Formulation}

	Robot Motion Planning is the problem of moving a robot from one position to another in the world. This problem is made difficult by several things: the kinematic structure of a robot, the complexity of its environment, how much information about the environment is known, the complexity of obstacles, and how much information about obstacles is known. 
	
	Real-time motion planning is the problem of performing motion planning on-line in order to react to a dynamic environment.
	
	Real-time motion planning involves several issues. 
	
	Most of the computational side

	
\section{Configuration Space}

A robot's \emph{configuration} is a vector specifying the values for each degree of freedom of the robot's kinematic structure. 

The \emph{Configuration Space} is an $n$ degree manifold mapping between a robot's transformations and Euclidean space. 


    

\section{Artificial Potential Fields}

In an artificial potential field approach, a robot is treated like a particle in a gradient field. The goal emits an attractive force that acts on the robot and the obstacles emit a repulsive force. The combination of forces results in a vector field. Figure~\ref{vector-field} illustrates an example.

At each location, a robot's motion is dictated by the magnitude and direction of the vector at the location.

\section{Elastic Roadmaps}


\section{Cell Decomposition Methods}
	
	doubly exponential (Springer handbook pg127)
	
\section{Sampling Based Methods}

Computing the exact configuration space in high dimensions becomes extremely expensive. This makes previous methods, such as potential fields and combinatorial roadmaps, inapplicable to motion planning problems of high dimensions, such as a 6-DOF manipulation problem. Sampling-based methods were introduced in order to handle motion planning problems with such high complexity. Sampling algorithms sacrifice completeness and optimality, but obtain higher performance results. 

Sampling based methods do not access the C-space directly. An associated collision detection algorithm will test a the robot at a sampled configuration with obstacles in the environment. Based on the result of collision detection, the sampling algorithm knows if a sample is free or obstacle space. After sampling many points, the result is an approximation of the C-space, rather than a complete description. 

Sampling has become the method of choice for most modern robotics applications. A sampling based method was first proposed in 1996 \cite{PRM} that builds a graph representation of the C-space approximation and then uses graph-search techniques to find a final path. A tree-based approach was introduced shortly after that could take kinodynamic constraints into account \cite{RRT}. These two approaches have been extended and iterated upon many times and remain the top approaches in the field.

\subsection{Probabilistic Roadmaps}

The basic Probabilistic Roadmaps algorithm \cite{PRM} works in two phases: learning and querying. 

\subsubsection{Learning Phase}

The goal of the \emph{learning} phase is to build the C-space approximation. An overview of the learning phase is summarized below.

\begin{algorithm}
\caption{PRM Learning Phase}
\begin{algorithmic}[1]
\State $N: $ number of nodes to include in the roadmap
\State $V \leftarrow \emptyset$ // Initialize set of vertices
\State $E \leftarrow \emptyset$ // Initialize set of edges
\State $i \leftarrow 0$
\While{$i < N$}
\State $q \leftarrow $ randomly sampled configuration
\If{$q \in C_{free}$}
	\State $V \leftarrow V \cup \{q\}$;
	\State $V_c \leftarrow $ neighborhood set of $q$;
	\ForAll{$v \in V_c$}
		\If{$Can\_Connect(v, q)$}
			\State $e \leftarrow $new edge($q,v$)
			\State $E \leftarrow E \cup \{e\}$
		\EndIf
	\EndFor
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

The goal is to build an undirected graph containing $N$ nodes. These nodes correspond the collision-free points in a robot's configuration space. When a point is sampled and determined to be collision-free, a neighborhood of points from the existing graph is found. For each of these neighborhood points, if a local planner can find a collision-free path from the sampled point to the neighborhood points, an edge is formed connecting the nodes.If a sampled node is found to be in collision, the node is thrown away and the algorithm samples again. 

A local planner is utilized in order to create edges within the graph. Designing a local planner can be difficult, however, because it still needs to plan in a high-dimensional space. Cheap and fast planners are possible since we do not need to consider a global objective. Even if fast local planners are not complete, they are desired over more powerful methods because they allow for more connections to be considered during the learning phase. They allow this because if a local planner is fast, then checking connections between many nodes is fast. Thus, the faster a local planner is, the more connections can be made in a small amount of time. It is desirable to sample as many nodes and make as many connections as possible since more nodes and connections will generally lead to a more accurate C-space approximation. For these reasons, local planners that connect nodes via straight lines are commonly used.

Determining the neighborhood of a node is based on the value of a distance function between two nodes. The distance function is closely related to the choice of local planner because the distance should be proportional to the chance that the local planner can connect the two nodes with a collision-free path. For straight line local planners, the distance function can be the Euclidean distance between the nodes' positions in the robot's workspace. For more complicated local planners, however, more involved distance functions must be defined.  

Narrow passages are a critical concern during the learning phase. A narrow passage is a region that is mostly enclosed by obstacles. These regions are of concern because it is difficult to sample inside of them and to find connections to nodes inside the regions. If a robot must pass through a narrow passage to reach its goal, then the learning phase may be prolonged to the point of being impractical. In Figure \ref{narrow}(a), the free space between the two obstacles could be considered a narrow passage. With uniform sampling, there is a small chance that a node in the passage will be found.  

The PRM method tries to address narrow passages by performing an \emph{expansion} step after constructing the graph, in order to improve the graph's connectivity. To accomplish that, nodes that lie in narrow passages are selected and an attempt to find neighboring points in $C_f$ is made. 

The difficulties in the expansion step is to identify which nodes lie in a narrow passage (those are the nodes that need expansion) and how to find neighboring points.

To find potential expansion nodes, a heuristic needs to be defined that predicts the likelihood of some node $c$ being unconnected. In \cite{PRM}, the following was used:

\begin{equation}
r_f(c) = \frac{f(c)}{n(c)+1}
\end{equation}

where $n(c)$ is the number of times the planner tried to connect node $c$ and $f(c)$ is the number of successful connects made to $c$. This function is the \emph{failure ratio} of node $c$.  

Random walks are a common method for actually expanding a node. A direction is chosen at random and the direction is followed until an obstacle is reached. An edge is then formed between node $c$ and a new node $n$ that is a node somewhere in between $c$ and the obstacle that was reached in the chosen direction. This process repeats by selecting new random directions for a pre-specified amount of time.

\subsubsection{Query Phase}

The \emph{query} phase searches the roadmap constructed during the learning phase to find a path from an initial configuration to a goal configuration. 

The first step in this phase is to connect the starting configuration, $s$, and goal configuration, $g$, to the roadmap. The local planner used in the learning phase is used for this task. The procedure for connecting $s$ to the roadmap, $R$, begins by identifying the closest node on $R$ to $s$. The local planner attempts to form a path between $s$ and the closest node. If it cannot find a path, the planner uses the next-closest node on $R$ to connect to $s$. This process repeats until a connection is successful. Once $s$ has been connected, the goal configuration $g$ is connected in the same way. Once both $s$ and $g$ are connected to $R$, any graph-search algorithm will return a path from $s$ to $g$ in the robot's configuration space.

\subsubsection{Further Discussion}

The PRM planner is considered \emph{probabilistically} complete. In most cases, it will not explore every point in the C-space. Given enough time, it will explore all points in the C-space and be able to determine if a path does not exist. 

Dynamic environments are difficult to address with the PRM approach. Constructing the roadmap can take significant computation time and is only useful for the state of the environment while constructing the roadmap. If any obstacles move, then the roadmap needs to be modified or completely remade based on the new state of the environment.


\subsection{Rapidly-Exploring Random Trees}

Rapidly-exploring Random Trees (RRT) is a popular sampling based approach to planning in high dimensional spaces \cite{RRT}. The key difference between RRT and PRM is that RRT uses a tree structure to approximate a robot's C-space, rather than the undirected graph structure used in PRM. This approach leads to several attractive features: it is suitable for handling non-holonomic and kinodynamic constraints, it requires few parameters, and is more apt to handle real-time planning in dynamic environments.

The state space contains both the set of the configurations and the set of possible velocities.  A single state would represent the robot's velocity at a particular configuration. Other interpretations are viable, however. States in the obstacle space should follow the state space representation, e.g. velocity bounds, configurations, etc.

A state transition function in the form $\dot{x} = f(x,u)$ must be defined to consider kinodynamic constraints. The inputs are a state, $x$, and an input, $u$, and the output is the derivative of the state over time. This function can be integrated in order to find the next state resulting from applying $u$ to $x$. This allows the algorithm to consider dynamics when building a path.

Pseudocode for building an RRT can be seen below:

\begin{algorithm}
\caption{RRT Overview}
\begin{algorithmic}[1]
\Function {Construct RRT}{$x_{init}$, $x_{goal}$, $\Delta t$} 
\State T.init($x_{init}$
\While{$x_{goal} \notin T$}
\State $x_{rand}$ = newly sampled state
\State $x_{near}$ = nearest neighbor of $x_{rand}$
\State $u$ = input needed to move from $x_{near}$ to $x_{rand}$
\State $x_{new}$ = $\{x_{near}, u, \Delta t\}$
\State $T.add\_vertex(x_{new})$
\State $T.add\_edge(x_{near}, x_{new}, u)$
\EndWhile
\State Return $T$
\EndFunction
\end{algorithmic}
\end{algorithm}

At each iteration, a new state, $x_{rand}$, is randomly sampled. The parent of $x_{rand}$ will be the vertex on the tree that is nearest to the sample. The control input, $u$, is then selected to move from $x_{near}$ to $x_{rand}$ without moving into any regions occupied by obstacles in the state space. The new state, $x_{new}$ is formed from the nearest neighbor, the control input, and a small time increment. The new node is added as a vertex on the tree and the edge connecting $x_{near}$ to $x_{new}$ by applying $u$ is added to the tree as a new edge. This process repeats until the goal state has been added to the tree. Since every state has only one parent on the RRT, adding the goal state to the tree means that a path has been found. 

The RRT approach has several nice properties. Similar to PRM, the RRT algorithm is probabilistically complete. The chance  of determining whether or not a path exists increases as times goes on. The expansion of states is biased towards unexplored areas because . As previously discussed, RRT is able to consider kinodynamic constraints. This is largely due to using a tree over an undirected graph. Since each state will have only one directed connection, it is easy to ensure that a robot's dynamic constraints will be satisfied as it move from state to state. The tree that is generated will always remain connected even in narrow passages. 

One of the most appealing aspects of RRT is that it is bias towards unexplored areas of a space. This occurs because the selection of new states is based on the nearest neighbor calculation. 

\section{Real-time Adaptive Motion Planning (RAMP)}

Real-time Adaptive Motion Planning (RAMP) \cite{RAMP} is a framework that utilizes evolutionary computation for real-time planning and execution in dynamic environments. 

Evolutionary computation is a field designed to leverage sophisticated data structures with genetic algorithms to search through a state space \cite{michalewicz2013genetic}. They are particularly suited to approximate optimization problems. One of the key difficulties in robot motion planning is extremely large state spaces. Sampling-based methods are able to find a path in large state spaces, but they can be far from optimal and re-sampling is expensive for real-time planning. An evolutionary computation approach allows us to change our set of samples very quickly and incorporate optimization into our state spaces searches. Using evolutionary computation for path planning was first proposed in \cite{EPN_Adaptive} and has since been extended to the motion planning framework RAMP.


\subsection{Modification}

A population of trajectories is maintained throughout the entire run time. Each trajectory in the population is a chromosome. At each \emph{generation}, 1-2 randomly selected chromosomes are modified via genetic operators. The new chromosome(s) may replace other trajectories in the population. 

The basic modification operators are described in \cite{EPN_Adaptive}. They are \emph{Insert}, \emph{Delete}, \emph{Swap}, \emph{Change}, and \emph{Crossover}. These modification operations are computationally inexpensive so it is possible to perform 100+ within a second. The operators can result in drastic changes to a path. This means that a new feasible path may be found in a very small amount of time, which facilitates real-time path planning that can react to changes in an environment. Modification operators can be added, removed, or replaced based on the application of the robot. For instance, a \emph{Stop} operator was introduced in \cite{RAMP} that stops the base of a mobile manipulator for a random amount of time. This operator promoted decoupling of the base and manipulator, which was desirable to exploit redundancy. 

The framework interweaves three separate procedures called planning cycles, control cycles, and sensing cycles. At each planning cycle (or \emph{generation}), the population of trajectories is modified. In later implementations (***Cite my own paper, what if not published?***), motion error is incorporated into the population during a planning cycle. The planning cycles occur as frequently as possible. Control cycles are procedures that select a trajectory from the population that will be executed by the robot and update the starting motion state of each trajectory in the population. The frequency of control cycles is adaptive based on constraints needed to satisfy in order to switch trajectories. Sensing cycles are procedures that update information about the environment.

\subsection{Evaluation}

Evolutionary computation utilizes an evaluation function to select the best chromosome from a population. In the RAMP framework, this corresponds to evaluating the population to choose the trajectory for a robot to execute. In RAMP, feasible trajectories are evaluated differently than infeasible trajectories. A trajectory's feasibility is determined by collision with obstacles and if all constraints can be satisfied when switching to the trajectory.

A feasible trajectory is evaluated by a weighted, normalized sum based on optimization criteria:

\begin{equation}
	Cost = \sum_{i=1}^{N} C_i\frac{V_i}{\alpha_i}
\end{equation}

where $C_i$ is a weight, $V_i$ is a value for an optimization criterion, and $\alpha_i$ is a normalization value. Common criteria are time costs, energy costs, orientation change, and manipulability costs.

Infeasible trajectories are trajectories that are in collision or cannot be executed due to not satisfying constraints. Rather than optimization criteria, they are evaluated based on penalties. For a mobile robot system, the following would be an evaluation function for infeasible trajectories:

\begin{equation}
Cost = P_T + P_\theta
\end{equation}
\begin{equation}
P_T = \frac{Q_T}{T_{coll}}
\end{equation}
\begin{equation}
P_\theta = Q_\theta\frac{\Delta\theta}{M}
\end{equation}

where $Q_T$ and $Q_θ$ are large constant values, $T_{coll}$ is the time
of the first collision in the trajectory, $\Delta\theta$ is the orientation change, and $M$ is a normalization term.

The evaluation for infeasible trajectories should be designed to differentiate which infeasible trajectories are better than others. For instance, the term $P_T$ ensures that trajectories with collision much later in time will be evaluated as better than trajectories with collision occurring very soon.

\subsection{Sensing}

Sensing cycles update the latest environment changes for the evaluation function. For dynamic obstacles, simple trajectories are predicted to use for collision detection in CT-space. An obstacle trajectory is predicted by assuming the sensed velocity is constant. Therefore, the predicted trajectory will be either a straight-line or circular arc. These are used for collision detection when evaluating the population. The obstacles may not follow what RAMP predicts, but future changes will be captured in future sensing cycles. Since sensing cycles occur frequently, using simple trajectories is sufficient for navigation, as shown through various experiments.

 


\section{Collision Detection}
	
	Collision detection is the problem of determining whether one or more objects in a virtual environment are in contact. 
	
	Collision detection is the most computationally expensive task in robot motion planning. 



\section{Conclusion}
    This is my Conclusion.


\bibliography{rtrmp_bib}
\bibliographystyle{unsrt}

\end{document}

