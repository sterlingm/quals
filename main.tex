\documentclass[10pt,conference]{ieeeconf}
\usepackage{algorithm}
\usepackage{algpseudocode}


\begin{document}


\nocite{PRM}


\author{Sterling McLeod}
\title {Real-time Robot Motion Planning: A Survey}
\date {2016}

\maketitle

\renewcommand{\algorithmicforall}{\textbf{for each}}

\section{Problem Formulation}

	Robot Motion Planning is the problem of moving a robot from one position to another in the world. This problem is made difficult by several things: the kinematic structure of a robot, the complexity of its environment, how much information about the environment is known, the complexity of obstacles, and how much information about obstacles is known. 
	
	Real-time motion planning is the problem of performing motion planning on-line in order to react to a dynamic environment.
	
	Real-time motion planning involves several issues. 
	
	Most of the computational side

	
\section{Configuration Space}

A robot's \emph{configuration} is a vector specifying the values for each degree of freedom of the robot's kinematic structure. 

The \emph{Configuration Space} is an $n$ degree manifold mapping between a robot's transformations and Euclidean space. 


    

\section{Artificial Potential Fields}

In an artificial potential field approach, a robot is treated like a particle in a gradient field. The goal emits an attractive force that acts on the robot and the obstacles emit a repulsive force. The combination of forces results in a vector field. Figure~\ref{vector-field} illustrates an example.

At each location, a robot's motion is dictated by the magnitude and direction of the vector at the location.

\section{Elastic Roadmaps}


\section{Combinatorial Methods}
	
	Combinatorial motion planning methods are complete planning algorithms that construct a roadmap in a known, continuous space in order to search through for path planning queries. These methods compute the exact configuration space for a robot and its environment in order to construct the roadmap. This class of algorithms works well for simple robotics problems, but does not scale up to many real-world applications seen today. 
	
\subsection{Roadmaps}
	
	Let $G$ be a graph structure of a topological space that maps to a robot's configuration space, $C_{free}$. The set $S$ is the points reachable in $C_{free}$ by $G$. In order for $G$ to be a roadmap, two conditions must be satisfied:
	\begin{enumerate}
	\item 
	It is simple to compute a path from any initial node to any goal node in the space represented by $G$.
	
	\item
	Given initial and goal configurations $q_I$ and $q_G$, respectively, in $C_{free}$, it is possible to connect corresponding nodes $s_1$ and $s_2$ in $S$. More formally, if there exists a path $\tau :[0,1] \rightarrow C_{free}$, such that $\tau (0)=q_I$ and $\tau (1)=q_G$, then there also exists a path $\tau'[0,1] \rightarrow S$, such that $\tau'(0)=s_1$ and $\tau'(1)=s_2$, where $s_1$ and $s_2$ are nodes on the roadmap.
	\end{enumerate}
	
	An extremely important implication of the second condition is that solutions to path-planning queries are not missed due to the roadmap not capturing the connectivity of the configuration space. Essentially, the second condition ensures that algorithms searching on a roadmap can be complete. The first condition makes it always possible to connect an initial and goal configuration to a roadmap. This is essentially because the initial and goal nodes are not connected to the roadmap when it is constructed. They are only connected when beginning a query.
	
\subsection{Cell Decomposition}

The goal of cell decomposition is to partition a topological space into cells that lie entirely in $C_{free}$. From such a partitioning, a roadmap can be constructed in order to reduce the path planning problem to a graph-search problem. There are several choices for decomposition. Some methods are best suited for polygonal spaces, some are better suited for higher-dimensions. However, all cell decompositions must satisfy three properties:

\begin{enumerate}
\item A path from any point in a cell to any point in a separate cell should lie in $C_{free}$.

\item Adjacency information is easy to extract.

\item Given any configuration $q$, calculating which cell $q$ lies in should be simple.
\end{enumerate}

The first condition is the most important. If it is known that the robot can move from one cell to another without encountering $C_{obs}$, then the problem is reduced to finding a path among a small number of cells, i.e. a graph-search problem. The second and third conditions are necessary to make the querying fast.

\subsubsection{Vertical Cell Decomposition}

Vertical Cell Decomposition is perhaps the most common method for cell decomposition in 2D. The method partitions the free C-space into triangles and trapezoids. These simple shapes represent the cells of $C_{free}$. 

At each vertex in $C_{obs}$, vertical rays are extended above and below the vertex until another points in $C_{obs}$ is reached. These rays will define edges for the polygonal cells that partition $C_{free}$. Refer to Figure \ref{narrow} for a visual description of the method. One can see that the polygons creating $C_{obs}$ can be either convex or concave and that the cells in $C_{free}$ will be either triangular or trapezoidal. 

Building a roadmap from the partitioning amounts to choosing sample points from each cell and connecting them to edges of the cell. More formally, a roadmap $G(V,E)$ is defined as follows: For every cell, $C_i$, define an interior point $q_i$. For each vertical edge in $C_i$, define a point $s_i$. Add the points $q_i$ and $s_i$ to $V$. Then, create an edge, $e_i$, between $q_i$ and the sample points on its cell's vertical edges. Add $e_i$ to $E$. The resulting graph is a roadmap that can be used for efficient path planning.

The running time of this algorithm is $O(nlogn)$ when using the \emph{line-sweep} principle. This principle is the idea of a line sweeping across the space and noting where there are interesting points in the space. In this application, the line is a vertical one and the interesting points are the vertices of obstacles.


To solve a path planning query, the initial and goal configurations, $q_I$ and $q_G$ respectively, need to be added to the roadmap. The third condition for cell decomposition listed in the previous section comes into play here. It should be simple to determine which cells $q_I$ and $q_G$ are in. Let $C_I$ and $C_G$ denote the cells that contain $q_I$ and $q_G$, respectively. Once $C_0$ and $C_G$ are identified, edges are found between the configurations and the corresponding cell's sample point. Thus, an edge is formed between $q_I$ and the sample point of $C_I$. Similarly, an edge is formed between $q_G$ and the sample point of $C_G$. Both edges are added to the roadmap $G(V,E)$. Graph search algorithms can be applied to the roadmap to find a path from $q_I$ and $q_G$ or find if a path does not exist.



	
\section{Sampling Based Methods}

Computing the exact configuration space in high dimensions becomes extremely expensive. This makes previous methods, such as potential fields and combinatorial roadmaps, inapplicable to motion planning problems of high dimensions, such as a 6-DOF manipulation problem. Sampling-based methods were introduced in order to handle motion planning problems with such high complexity. Sampling algorithms sacrifice completeness and optimality, but obtain higher performance results. 

Sampling based methods do not access the C-space directly. An associated collision detection algorithm will test a the robot at a sampled configuration with obstacles in the environment. Based on the result of collision detection, the sampling algorithm knows if a sample is free or obstacle space. After sampling many points, the result is an approximation of the C-space, rather than a complete description. 

Sampling has become the method of choice for most modern robotics applications. A sampling based method was first proposed in 1996 \cite{PRM} that builds a graph representation of the C-space approximation and then uses graph-search techniques to find a final path. A tree-based approach was introduced shortly after that could take kinodynamic constraints into account \cite{RRT}. These two approaches have been extended and iterated upon many times and remain the top approaches in the field.

\subsection{Probabilistic Roadmaps}

The basic Probabilistic Roadmaps algorithm \cite{PRM} works in two phases: learning and querying. 

\subsubsection{Learning Phase}

The goal of the \emph{learning} phase is to build the C-space approximation. An overview of the learning phase is summarized below.

\begin{algorithm}
\caption{PRM Learning Phase}
\begin{algorithmic}[1]
\State $N: $ number of nodes to include in the roadmap
\State $V \leftarrow \emptyset$ // Initialize set of vertices
\State $E \leftarrow \emptyset$ // Initialize set of edges
\State $i \leftarrow 0$
\While{$i < N$}
\State $q \leftarrow $ randomly sampled configuration
\If{$q \in C_{free}$}
	\State $V \leftarrow V \cup \{q\}$;
	\State $V_c \leftarrow $ neighborhood set of $q$;
	\ForAll{$v \in V_c$}
		\If{$Can\_Connect(v, q)$}
			\State $e \leftarrow $new edge($q,v$)
			\State $E \leftarrow E \cup \{e\}$
		\EndIf
	\EndFor
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

The goal is to build an undirected graph containing $N$ nodes. These nodes correspond the collision-free points in a robot's configuration space. When a point is sampled and determined to be collision-free, a neighborhood of points from the existing graph is found. For each of these neighborhood points, if a local planner can find a collision-free path from the sampled point to the neighborhood points, an edge is formed connecting the nodes.If a sampled node is found to be in collision, the node is thrown away and the algorithm samples again. 

A local planner is utilized in order to create edges within the graph. Designing a local planner can be difficult, however, because it still needs to plan in a high-dimensional space. Cheap and fast planners are possible since we do not need to consider a global objective. Even if fast local planners are not complete, they are desired over more powerful methods because they allow for more connections to be considered during the learning phase. They allow this because if a local planner is fast, then checking connections between many nodes is fast. Thus, the faster a local planner is, the more connections can be made in a small amount of time. It is desirable to sample as many nodes and make as many connections as possible since more nodes and connections will generally lead to a more accurate C-space approximation. For these reasons, local planners that connect nodes via straight lines are commonly used.

Determining the neighborhood of a node is based on the value of a distance function between two nodes. The distance function is closely related to the choice of local planner because the distance should be proportional to the chance that the local planner can connect the two nodes with a collision-free path. For straight line local planners, the distance function can be the Euclidean distance between the nodes' positions in the robot's workspace. For more complicated local planners, however, more involved distance functions must be defined.  

Narrow passages are a critical concern during the learning phase. A narrow passage is a region that is mostly enclosed by obstacles. These regions are of concern because it is difficult to sample inside of them and to find connections to nodes inside the regions. If a robot must pass through a narrow passage to reach its goal, then the learning phase may be prolonged to the point of being impractical. In Figure \ref{narrow}(a), the free space between the two obstacles could be considered a narrow passage. With uniform sampling, there is a small chance that a node in the passage will be found.  

The PRM method tries to address narrow passages by performing an \emph{expansion} step after constructing the graph, in order to improve the graph's connectivity. To accomplish that, nodes that lie in narrow passages are selected and an attempt to find neighboring points in $C_f$ is made. 

The difficulties in the expansion step is to identify which nodes lie in a narrow passage (those are the nodes that need expansion) and how to find neighboring points.

To find potential expansion nodes, a heuristic needs to be defined that predicts the likelihood of some node $c$ being unconnected. In \cite{PRM}, the following was used:

\begin{equation}
r_f(c) = \frac{f(c)}{n(c)+1}
\end{equation}

where $n(c)$ is the number of times the planner tried to connect node $c$ and $f(c)$ is the number of successful connects made to $c$. This function is the \emph{failure ratio} of node $c$.  

Random walks are a common method for actually expanding a node. A direction is chosen at random and the direction is followed until an obstacle is reached. An edge is then formed between node $c$ and a new node $n$ that is a node somewhere in between $c$ and the obstacle that was reached in the chosen direction. This process repeats by selecting new random directions for a pre-specified amount of time.

\subsubsection{Query Phase}

The \emph{query} phase searches the roadmap constructed during the learning phase to find a path from an initial configuration to a goal configuration. 

The first step in this phase is to connect the starting configuration, $s$, and goal configuration, $g$, to the roadmap. The local planner used in the learning phase is used for this task. The procedure for connecting $s$ to the roadmap, $R$, begins by identifying the closest node on $R$ to $s$. The local planner attempts to form a path between $s$ and the closest node. If it cannot find a path, the planner uses the next-closest node on $R$ to connect to $s$. This process repeats until a connection is successful. Once $s$ has been connected, the goal configuration $g$ is connected in the same way. Once both $s$ and $g$ are connected to $R$, any graph-search algorithm will return a path from $s$ to $g$ in the robot's configuration space.

\subsubsection{Further Discussion}

The PRM planner is considered \emph{probabilistically} complete. In most cases, it will not explore every point in the C-space. Given enough time, it will explore all points in the C-space and be able to determine if a path does not exist. 

Dynamic environments are difficult to address with the PRM approach. Constructing the roadmap can take significant computation time and is only useful for the state of the environment while constructing the roadmap. If any obstacles move, then the roadmap needs to be modified or completely remade based on the new state of the environment.


\subsection{Rapidly-Exploring Random Trees}

Rapidly-exploring Random Trees (RRT) is a popular sampling based approach to planning in high dimensional spaces \cite{RRT}. The key difference between RRT and PRM is that RRT uses a tree structure to approximate a robot's C-space, rather than the undirected graph structure used in PRM. This approach leads to several attractive features: it is suitable for handling non-holonomic and kinodynamic constraints, it requires few parameters, and is more apt to handle real-time planning in dynamic environments.

The state space contains both the set of the configurations and the set of possible velocities.  A single state would represent the robot's velocity at a particular configuration. Other interpretations are viable, however. States in the obstacle space should follow the state space representation, e.g. velocity bounds, configurations, etc.

A state transition function in the form $\dot{x} = f(x,u)$ must be defined to consider kinodynamic constraints. The inputs are a state, $x$, and an input, $u$, and the output is the derivative of the state over time. This function can be integrated in order to find the next state resulting from applying $u$ to $x$. This allows the algorithm to consider dynamics when building a path.

Pseudocode for building an RRT can be seen below:

\begin{algorithm}
\caption{RRT Overview}
\begin{algorithmic}[1]
\Function {Construct RRT}{$x_{init}$, $x_{goal}$, $\Delta t$} 
\State T.init($x_{init}$
\While{$x_{goal} \notin T$}
\State $x_{rand}$ = newly sampled state
\State $x_{near}$ = nearest neighbor of $x_{rand}$
\State $u$ = input needed to move from $x_{near}$ to $x_{rand}$
\State $x_{new}$ = $\{x_{near}, u, \Delta t\}$
\State $T.add\_vertex(x_{new})$
\State $T.add\_edge(x_{near}, x_{new}, u)$
\EndWhile
\State Return $T$
\EndFunction
\end{algorithmic}
\end{algorithm}

At each iteration, a new state, $x_{rand}$, is randomly sampled. The parent of $x_{rand}$ will be the vertex on the tree that is nearest to the sample. The control input, $u$, is then selected to move from $x_{near}$ to $x_{rand}$ without moving into any regions occupied by obstacles in the state space. The new state, $x_{new}$ is formed from the nearest neighbor, the control input, and a small time increment. The new node is added as a vertex on the tree and the edge connecting $x_{near}$ to $x_{new}$ by applying $u$ is added to the tree as a new edge. This process repeats until the goal state has been added to the tree. Since every state has only one parent on the RRT, adding the goal state to the tree means that a path has been found. 

The RRT approach has several nice properties. Similar to PRM, the RRT algorithm is probabilistically complete. The chance  of determining whether or not a path exists increases as times goes on. As previously discussed, RRT is able to consider kinodynamic constraints. This is largely due to using a tree over an undirected graph. Since each state will have only one directed connection, it is easy to ensure that a robot's dynamic constraints will be satisfied as it move from state to state. Another attractive property is that the tree will always remain connected, even in narrow passages. Graphs constructed with the PRM are not guaranteed to remain connected because the connections are based on a vertex's neighborhood. If there are no existing vertices nearby the new vertex, then the vertex will have no connections, but will still be added to the graph.

One of the most appealing aspects of RRT is that it is bias towards unexplored areas of a space. This occurs because the selection of new states is based on the nearest neighbor calculation.

RRT has been applied to many constraint-based planning problems. In the figure below, several examples of RRTs are shown for different planning problems.

\section{Real-time Adaptive Motion Planning (RAMP)}

Real-time Adaptive Motion Planning (RAMP) \cite{RAMP} is a framework that utilizes evolutionary computation for real-time planning and execution in dynamic environments. 

Evolutionary computation is a field designed to leverage sophisticated data structures with genetic algorithms to search through a state space \cite{michalewicz2013genetic}. They are particularly suited to approximate optimization problems. One of the key difficulties in robot motion planning is extremely large state spaces. Sampling-based methods are able to find a path in large state spaces, but they can be far from optimal and re-sampling is expensive for real-time planning. An evolutionary computation approach allows us to change our set of samples very quickly and incorporate optimization into our state spaces searches. Using evolutionary computation for path planning was first proposed in \cite{EPN_Adaptive} and has since been extended to the motion planning framework RAMP.


\subsection{Modification}

A population of trajectories is maintained throughout the entire run time. Each trajectory in the population is a chromosome. At each \emph{generation}, 1-2 randomly selected chromosomes are modified via genetic operators. The new chromosome(s) may replace other trajectories in the population. 

The basic modification operators are described in \cite{EPN_Adaptive}. They are \emph{Insert}, \emph{Delete}, \emph{Swap}, \emph{Change}, and \emph{Crossover}. These modification operations are computationally inexpensive so it is possible to perform 100+ within a second. The operators can result in drastic changes to a path. This means that a new feasible path may be found in a very small amount of time, which facilitates real-time path planning that can react to changes in an environment. Modification operators can be added, removed, or replaced based on the application of the robot. For instance, a \emph{Stop} operator was introduced in \cite{RAMP} that stops the base of a mobile manipulator for a random amount of time. This operator promoted decoupling of the base and manipulator, which was desirable to exploit redundancy. 

The framework interweaves three separate procedures called planning cycles, control cycles, and sensing cycles. At each planning cycle (or \emph{generation}), the population of trajectories is modified. In later implementations (***Cite my own paper, what if not published?***), motion error is incorporated into the population during a planning cycle. The planning cycles occur as frequently as possible. Control cycles are procedures that select a trajectory from the population that will be executed by the robot and update the starting motion state of each trajectory in the population. The frequency of control cycles is adaptive based on constraints needed to satisfy in order to switch trajectories. Sensing cycles are procedures that update information about the environment.

\subsection{Evaluation}

Evolutionary computation utilizes an evaluation function to select the best chromosome from a population. In the RAMP framework, this corresponds to evaluating the population to choose the trajectory for a robot to execute. In RAMP, feasible trajectories are evaluated differently than infeasible trajectories. A trajectory's feasibility is determined by collision with obstacles and if all constraints can be satisfied when switching to the trajectory.

A feasible trajectory is evaluated by a weighted, normalized sum based on optimization criteria:

\begin{equation}
	Cost = \sum_{i=1}^{N} C_i\frac{V_i}{\alpha_i}
\end{equation}

where $C_i$ is a weight, $V_i$ is a value for an optimization criterion, and $\alpha_i$ is a normalization value. Common criteria are time costs, energy costs, orientation change, and manipulability costs.

Infeasible trajectories are trajectories that are in collision or cannot be executed due to not satisfying constraints. Rather than optimization criteria, they are evaluated based on penalties. For a mobile robot system, the following would be an evaluation function for infeasible trajectories:

\begin{equation}
Cost = P_T + P_\theta
\end{equation}
\begin{equation}
P_T = \frac{Q_T}{T_{coll}}
\end{equation}
\begin{equation}
P_\theta = Q_\theta\frac{\Delta\theta}{M}
\end{equation}

where $Q_T$ and $Q_θ$ are large constant values, $T_{coll}$ is the time
of the first collision in the trajectory, $\Delta\theta$ is the orientation change, and $M$ is a normalization term.

The evaluation for infeasible trajectories should be designed to differentiate which infeasible trajectories are better than others. For instance, the term $P_T$ ensures that trajectories with collision much later in time will be evaluated as better than trajectories with collision occurring very soon.

\subsection{Sensing}

Sensing cycles update the latest environment changes for the evaluation function. For dynamic obstacles, simple trajectories are predicted to use for collision detection in CT-space. An obstacle trajectory is predicted by assuming the sensed velocity is constant. Therefore, the predicted trajectory will be either a straight-line or circular arc. These are used for collision detection when evaluating the population. The obstacles may not follow what RAMP predicts, but future changes will be captured in future sensing cycles. Since sensing cycles occur frequently, using simple trajectories is sufficient for navigation, as shown through various experiments.

 


\section{Collision Detection}
	
	Collision detection is the problem of determining whether one or more objects in a virtual environment are in contact. 
	
	Collision detection is the most computationally expensive task in robot motion planning. 



\section{Conclusion}
    This is my Conclusion.


\bibliography{rtrmp_bib}
\bibliographystyle{unsrt}

\end{document}

